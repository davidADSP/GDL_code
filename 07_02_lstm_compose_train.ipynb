{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose: Training a model to generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import note, chord\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from models.RNNAttention import get_distinct, create_lookups, prepare_sequences, get_music_list, create_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'compose'\n",
    "run_id = '0006'\n",
    "music_name = 'cello'\n",
    "\n",
    "run_folder = 'run/{}/'.format(section)\n",
    "run_folder += '_'.join([run_id, music_name])\n",
    "\n",
    "\n",
    "store_folder = os.path.join(run_folder, 'store')\n",
    "data_folder = os.path.join('data', music_name)\n",
    "\n",
    "if not os.path.exists(run_folder):\n",
    "    os.mkdir(run_folder)\n",
    "    os.mkdir(os.path.join(run_folder, 'store'))\n",
    "    os.mkdir(os.path.join(run_folder, 'output'))\n",
    "    os.mkdir(os.path.join(run_folder, 'weights'))\n",
    "    os.mkdir(os.path.join(run_folder, 'viz'))\n",
    "    \n",
    "\n",
    "\n",
    "mode = 'build' # 'load' # \n",
    "\n",
    "# data params\n",
    "intervals = range(1)\n",
    "seq_len = 32\n",
    "\n",
    "# model params\n",
    "embed_size = 100\n",
    "rnn_units = 256\n",
    "use_attention = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'build':\n",
    "    \n",
    "    music_list, parser = get_music_list(data_folder)\n",
    "    print(len(music_list), 'files in total')\n",
    "\n",
    "    notes = []\n",
    "    durations = []\n",
    "\n",
    "    for i, file in enumerate(music_list):\n",
    "        print(i+1, \"Parsing %s\" % file)\n",
    "        original_score = parser.parse(file).chordify()\n",
    "        \n",
    "\n",
    "        for interval in intervals:\n",
    "\n",
    "            score = original_score.transpose(interval)\n",
    "\n",
    "            notes.extend(['START'] * seq_len)\n",
    "            durations.extend([0]* seq_len)\n",
    "\n",
    "            for element in score.flat:\n",
    "                \n",
    "                if isinstance(element, note.Note):\n",
    "                    if element.isRest:\n",
    "                        notes.append(str(element.name))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "                    else:\n",
    "                        notes.append(str(element.nameWithOctave))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "\n",
    "                if isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n",
    "                    durations.append(element.duration.quarterLength)\n",
    "\n",
    "    with open(os.path.join(store_folder, 'notes'), 'wb') as f:\n",
    "        pickle.dump(notes, f) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open(os.path.join(store_folder, 'durations'), 'wb') as f:\n",
    "        pickle.dump(durations, f) \n",
    "else:\n",
    "    with open(os.path.join(store_folder, 'notes'), 'rb') as f:\n",
    "        notes = pickle.load(f) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open(os.path.join(store_folder, 'durations'), 'rb') as f:\n",
    "        durations = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distinct sets of notes and durations\n",
    "note_names, n_notes = get_distinct(notes)\n",
    "duration_names, n_durations = get_distinct(durations)\n",
    "distincts = [note_names, n_notes, duration_names, n_durations]\n",
    "\n",
    "with open(os.path.join(store_folder, 'distincts'), 'wb') as f:\n",
    "    pickle.dump(distincts, f)\n",
    "\n",
    "# make the lookup dictionaries for notes and dictionaries and save\n",
    "note_to_int, int_to_note = create_lookups(note_names)\n",
    "duration_to_int, int_to_duration = create_lookups(duration_names)\n",
    "lookups = [note_to_int, int_to_note, duration_to_int, int_to_duration]\n",
    "\n",
    "with open(os.path.join(store_folder, 'lookups'), 'wb') as f:\n",
    "    pickle.dump(lookups, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nnote_to_int')\n",
    "note_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nduration_to_int')\n",
    "duration_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the sequences used by the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input, network_output = prepare_sequences(notes, durations, lookups, distincts, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pitch input')\n",
    "print(network_input[0][0])\n",
    "print('duration input')\n",
    "print(network_input[1][0])\n",
    "print('pitch output')\n",
    "print(network_output[0][0])\n",
    "print('duration output')\n",
    "print(network_output[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the structure of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, att_model = create_network(n_notes, n_durations, embed_size, rnn_units, use_attention)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently errors in TF2.2\n",
    "#plot_model(model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "# model.load_weights(os.path.join(weights_folder, \"weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    , early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "model.fit(network_input, network_output\n",
    "          , epochs=2000000, batch_size=32\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdl_code",
   "language": "python",
   "name": "gdl_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
